{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95096f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sodapy\n",
      "  Downloading sodapy-2.2.0-py2.py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: requests>=2.28.1 in /home/codespace/.local/lib/python3.12/site-packages (from sodapy) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.28.1->sodapy) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.28.1->sodapy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.28.1->sodapy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests>=2.28.1->sodapy) (2025.7.9)\n",
      "Downloading sodapy-2.2.0-py2.py3-none-any.whl (15 kB)\n",
      "Installing collected packages: sodapy\n",
      "Successfully installed sodapy-2.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sodapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "902bbeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sodapy import Socrata\n",
    "\n",
    "import pandas as pd\n",
    "from sodapy import Socrata\n",
    "\n",
    "\n",
    "\n",
    "# Unauthenticated client only works with public data sets. Note 'None'\n",
    "# in place of application token, and no username or password:\n",
    "\n",
    "\n",
    "# Example authenticated client (needed for non-public datasets):\n",
    "client = Socrata(\"www.datos.gov.co\",\n",
    "                  \"tcU2fieqxe5EiHJE2OcqmSrPq\",\n",
    "                  username=\"##\",\n",
    "                  password=\"##\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334c4d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns \n",
    "#overview=client.get(\"p6dx-8zbt\")\n",
    "#overview_pd=pd.DataFrame(overview)\n",
    "#overview_pd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51dcb09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sqlalchemy in c:\\programdata\\anaconda3\\lib\\site-packages (2.0.39)\n",
      "Collecting psycopg2-binary\n",
      "  Downloading psycopg2_binary-2.9.10-cp313-cp313-win_amd64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from sqlalchemy) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sqlalchemy) (4.12.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading psycopg2_binary-2.9.10-cp313-cp313-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 1.0/2.6 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.6/2.6 MB 7.3 MB/s eta 0:00:00\n",
      "Installing collected packages: psycopg2-binary\n",
      "Successfully installed psycopg2-binary-2.9.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sqlalchemy psycopg2-binary pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851f795f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e43efc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Inserted 110 records (excluding duplicates)\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import text\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# 1. Date for yesterday\n",
    "fifteen = (datetime.today() - timedelta(days=15)).strftime('%Y-%m-%d')\n",
    "\n",
    "# 2. API query\n",
    "endpoint = \"https://www.datos.gov.co/resource/p6dx-8zbt.json\"\n",
    "query = f\"\"\"\n",
    "SELECT entidad, nombre_del_procedimiento,\n",
    "    descripci_n_del_procedimiento, fase, fecha_de_ultima_publicaci, precio_base,\n",
    "    proveedores_invitados, proveedores_con_invitacion, visualizaciones_del,\n",
    "    proveedores_que_manifestaron, id_estado_del_procedimiento,\n",
    "    codigo_principal_de_categoria, urlproceso, estado_del_procedimiento, adjudicado,\n",
    "    estado_resumen, fecha_adjudicacion, fecha_de_publicacion, referencia_del_proceso\n",
    "WHERE adjudicado = 'No'\n",
    "AND id_estado_del_procedimiento = '50'\n",
    "AND fecha_de_publicacion > '{fifteen}'\n",
    "\"\"\"\n",
    "\n",
    "# 3. Fetch all pages\n",
    "limit, offset, all_data = 1000, 0, []\n",
    "\n",
    "while True:\n",
    "    params = {\"$query\": query + f\"\\nLIMIT {limit} OFFSET {offset}\"}\n",
    "    response = requests.get(endpoint, params=params)\n",
    "    response.raise_for_status()\n",
    "    batch = response.json()\n",
    "    if not batch:\n",
    "        break\n",
    "    all_data.extend(batch)\n",
    "    offset += limit\n",
    "\n",
    "df = pd.DataFrame(all_data)\n",
    "\n",
    "\n",
    "# 4.1 Ensure all columns exist and missing values are set to None\n",
    "expected_columns = [\n",
    "    \"referencia_del_proceso\", \"entidad\", \"nombre_del_procedimiento\",\n",
    "    \"descripci_n_del_procedimiento\", \"fase\", \"fecha_de_ultima_publicaci\",\n",
    "    \"precio_base\", \"proveedores_invitados\", \"proveedores_con_invitacion\",\n",
    "    \"visualizaciones_del\", \"proveedores_que_manifestaron\",\n",
    "    \"id_estado_del_procedimiento\", \"codigo_principal_de_categoria\",\n",
    "    \"urlproceso\", \"estado_del_procedimiento\", \"adjudicado\",\n",
    "    \"estado_resumen\", \"fecha_adjudicacion\", \"fecha_de_publicacion\"\n",
    "]\n",
    "\n",
    "# Add any missing columns with default None\n",
    "for col in expected_columns:\n",
    "    if col not in df.columns:\n",
    "        df[col] = None\n",
    "\n",
    "# Replace all NaNs/missing with None (for SQL compatibility)\n",
    "df = df.where(pd.notnull(df), None)\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "# 4.2 Flatten nested structures in URL column\n",
    "def extract_url(value):\n",
    "    if isinstance(value, dict) and 'url' in value:\n",
    "        return value['url']\n",
    "    return value\n",
    "\n",
    "if 'urlproceso' in df.columns:\n",
    "    df['urlproceso'] = df['urlproceso'].apply(extract_url)\n",
    "\n",
    "# Also handle other potential nested columns\n",
    "for col in df.columns:\n",
    "    if df[col].apply(lambda x: isinstance(x, dict)).any():\n",
    "        df[col] = df[col].apply(lambda x: json.dumps(x) if isinstance(x, dict) else x)\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "# 4. Save to PostgreSQL with deduplication\n",
    "engine = create_engine(\"postgresql://daplauser:Daviplata2709@sdavi.postgres.database.azure.com:5432/tendersdb\")\n",
    "\n",
    "# Use raw connection to use ON CONFLICT\n",
    "with engine.begin() as conn:\n",
    "    for _, row in df.iterrows():\n",
    "        conn.execute(\n",
    "            text(\"\"\"\n",
    "                INSERT INTO tenders (\n",
    "                    referencia_del_proceso, entidad, nombre_del_procedimiento,\n",
    "                    descripci_n_del_procedimiento, fase, fecha_de_ultima_publicaci,\n",
    "                    precio_base, proveedores_invitados, proveedores_con_invitacion,\n",
    "                    visualizaciones_del, proveedores_que_manifestaron,\n",
    "                    id_estado_del_procedimiento, codigo_principal_de_categoria,\n",
    "                    urlproceso, estado_del_procedimiento, adjudicado,\n",
    "                    estado_resumen, fecha_adjudicacion, fecha_de_publicacion\n",
    "                )\n",
    "                VALUES (\n",
    "                    :referencia_del_proceso, :entidad, :nombre_del_procedimiento,\n",
    "                    :descripci_n_del_procedimiento, :fase, :fecha_de_ultima_publicaci,\n",
    "                    :precio_base, :proveedores_invitados, :proveedores_con_invitacion,\n",
    "                    :visualizaciones_del, :proveedores_que_manifestaron,\n",
    "                    :id_estado_del_procedimiento, :codigo_principal_de_categoria,\n",
    "                    :urlproceso, :estado_del_procedimiento, :adjudicado,\n",
    "                    :estado_resumen, :fecha_adjudicacion, :fecha_de_publicacion\n",
    "                )\n",
    "                ON CONFLICT (referencia_del_proceso) DO NOTHING\n",
    "            \"\"\"),\n",
    "            row.to_dict()\n",
    "        )\n",
    "\n",
    "print(f\"✅ Inserted {len(df)} records (excluding duplicates)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3a99a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.4 Save to PostgreSQL with truncation\n",
    "engine = create_engine(\"postgresql://daplauser:Daviplata2709@sdavi.postgres.database.azure.com:5432/tendersdb\")\n",
    "\n",
    "with engine.begin() as conn:\n",
    "    # ⚠️ WARNING: This deletes all existing data!\n",
    "    conn.execute(text(\"TRUNCATE TABLE tenders RESTART IDENTITY\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
